{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "317e9c90-9d46-4133-babf-60e25cd5ee5f",
   "metadata": {},
   "source": [
    "## Intro to Neural Nets : Self-learning\n",
    "### Abstract\n",
    "The purpose of this notebook is to learn the basics of how neural networks work.\n",
    "I will be working through Packt's *Machine Learning with Pytorch and Scikit-learn*,\n",
    "starting with chapter 2's introduction to building simple discrete neurons, to chapter\n",
    "11's exercise on building a multilayer perceptron to classify handwritten characters\n",
    "in the MNIST dataset.\n",
    "\n",
    "The resulting code is meant to be educational and illustrate concepts, not be \n",
    "performative; the final neural net won't be remotely optimized.  A later notebook will \n",
    "focus on implimenting a neural network in a more functional and practical manner using\n",
    "numpy's optimized data structures and matrix functions.\n",
    "\n",
    "*(additionally, I feel I need to review my linear algebra, so rather than leverage numpy \n",
    "I will instead be writing my own linear algebra functions in pure python)*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f79954b-5e3a-4801-a981-8f4267e42763",
   "metadata": {},
   "source": [
    "### Part 1: Building a neuron \n",
    "At it's most basic, an artificial neuron consists of three main components: weights; a bias; and an activation function.\n",
    "- **weights:** Each neuron has one or more inputs. Each of these inputs is multiplied by a weight that determines how much and in what direction each of these inputs should affect the neuron's output. After the inputs have been weighed, they are then summed.\n",
    "- **bias :** After the sum of weighed inputs has been computed, an additional value (+ or -) that is added to that sum.  This value makes it easier or harder for this neuron to turn on, effectively biassing it towards one state or another.\n",
    "- **activation function:** Because the weights and biases are unbound, the sum of the biases and weighed inputs is also unbound in both directions -- this is unwanted.  The activation function is a final step that conditions the sum in such a manner that it is bound to be no less than 0 and possibly no more than 1 depending on the exact activation function used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3e2cb6b-8714-435b-94d3-de9b1147b5f6",
   "metadata": {},
   "source": [
    "First we need to be able to instantiate a neuron with those 3 basic components.  Let's write a constructor that initializes it with random weights and biases:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2c763a26-37f0-4c40-b1ad-b177ebf67aa8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Callable\n",
    "from random import random\n",
    "\n",
    "class Neuron():\n",
    "\n",
    "    def __init__(self, num_of_inputs: int, activation_function: str):\n",
    "        \"\"\"Instantiates a neuron with random weights and bias\"\"\"\n",
    "\n",
    "        # validate args:\n",
    "        if num_of_inputs < 1:\n",
    "            print(\"there must be more than 1 input to a neuron\")\n",
    "            return\n",
    "\n",
    "        self.num_of_inputs = num_of_inputs\n",
    "        self.weights = [random() for i in range(num_of_inputs)]\n",
    "        self.bias  = random()\n",
    "        if activation_function not in Neuron.activation_functions:\n",
    "            print(\"Invalid activation function\")\n",
    "            del(self)\n",
    "            return\n",
    "        if activation_function == \"RELU\":\n",
    "            self.activation_function = Neuron.RELU\n",
    "\n",
    "\n",
    "\n",
    "# For an activation function, let's start with a simple RELU.\n",
    "# Lets do this by extending the Neuron class with a class RELU method\n",
    "# NOTE: Extending a class via self-inheritance isn't something I'd typically do!\n",
    "class Neuron(Neuron):\n",
    "    \n",
    "    @classmethod\n",
    "    def RELU(self,sum_of_weighed_inputs_and_bias):\n",
    "        if sum_of_weighed_inputs_and_bias < 0:\n",
    "            return(0)\n",
    "        else: \n",
    "            return(sum_of_weighed_inputs_and_bias\n",
    "                   \n",
    "    activation_functions = [\"RELU\"]\n",
    "\n",
    "\n",
    "# now let's instantiate and test a neuron with 5 inputs:\n",
    "num_of_inputs = 5\n",
    "test_neuron = Neuron(num_of_inputs,\"RELU\")\n",
    "assert(len(test_neuron.weights) == num_of_inputs)\n",
    "assert(test_neuron.activation_function(-5) == 0)\n",
    "assert(test_neuron.activation_function(100) == 100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7d4b0ed-ce10-40c4-907e-7d5f809abb39",
   "metadata": {},
   "source": [
    "Now we need to add a method to allow this neuron to take a vector of inputs and compute an output.  This involves multiplying the transposed weights vector by the inputs vector and then adding the bias.  So first we need a function to transpose a matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76f21bed-ac1a-403d-a3fa-ecd8b898a3e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_transpose(matrix):\n",
    "    #test that matrix is only 2-dimensional:\n",
    "    try\n",
    "    #test that all elements are numeric:\n",
    "\n",
    "    #test that all\n",
    "    len_y = len(matrix)\n",
    "    len_x = len(matrix[0])\n",
    "\n",
    "matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a4302c14-9823-498e-93a7-d813729a5c4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neuron(Neuron):\n",
    "\n",
    "    def compute(self, inputs: list[float]):\n",
    "        #Implementation\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ee8a7df-c719-4bdb-979f-12ba97f87a07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['RELU',\n",
       " '__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getstate__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " 'activation_function',\n",
       " 'activation_functions',\n",
       " 'bias',\n",
       " 'num_of_inputs',\n",
       " 'weights']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b263399-9f5d-4b82-9e19-b41a9af442a1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
